{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function calling\n",
    "\n",
    "This new feature proves beneficial in a wide array of situations. It can assist in designing chatbots capable of interacting with various APIs, facilitate task automation, and enable extraction of organized information from inputs expressed in natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.201)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.4.48)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: langchainplus-sdk>=0.0.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.0.9)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade langchain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure you got the AT LEAST Version 0.0.200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of the langchain library is 0.0.201.\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "\n",
    "def print_version(package_name):\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(package_name).version\n",
    "        print(f\"The version of the {package_name} library is {version}.\")\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        print(f\"The {package_name} library is not installed.\")\n",
    "\n",
    "\n",
    "print_version(\"langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.environ.get(\"API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to define a function. This one mimics a database query with a \"fake\" price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pizza_info(pizza_name: str):\n",
    "    pizza_info = {\n",
    "        \"name\": pizza_name,\n",
    "        \"price\": \"10.99\",\n",
    "    }\n",
    "    return json.dumps(pizza_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_pizza_info\",\n",
    "        \"description\": \"Get name and price of a pizza of the restaurant\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"pizza_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the pizza, e.g. Salami\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"pizza_name\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(query):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=[{\"role\": \"user\", \"content\": query}],\n",
    "        functions=functions,\n",
    "    )\n",
    "    message = response[\"choices\"][0][\"message\"]\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x1df198b3fb0> JSON: {\n",
       "  \"content\": \"The capital of France is Paris.\",\n",
       "  \"role\": \"assistant\"\n",
       "}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"What is the capital of france?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x1df198b33b0> JSON: {\n",
       "  \"content\": null,\n",
       "  \"function_call\": {\n",
       "    \"arguments\": \"{\\n  \\\"pizza_name\\\": \\\"Salami\\\"\\n}\",\n",
       "    \"name\": \"get_pizza_info\"\n",
       "  },\n",
       "  \"role\": \"assistant\"\n",
       "}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How much does pizza salami cost?\"\n",
    "message = chat(query)\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "{'name': None, 'price': '10.99'} is not of type 'string' - 'messages.2.content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m     function_name \u001b[39m=\u001b[39m message[\u001b[39m\"\u001b[39m\u001b[39mfunction_call\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m     function_response \u001b[39m=\u001b[39m get_pizza_info(\n\u001b[0;32m      4\u001b[0m         pizza_name\u001b[39m=\u001b[39mmessage\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mpizza_name\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m      5\u001b[0m     )\n\u001b[1;32m----> 7\u001b[0m     second_response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      8\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo-0613\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      9\u001b[0m         messages\u001b[39m=\u001b[39;49m[\n\u001b[0;32m     10\u001b[0m             {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: query},\n\u001b[0;32m     11\u001b[0m             message,\n\u001b[0;32m     12\u001b[0m             {\n\u001b[0;32m     13\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mfunction\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     14\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_name,\n\u001b[0;32m     15\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_response,\n\u001b[0;32m     16\u001b[0m             },\n\u001b[0;32m     17\u001b[0m         ],\n\u001b[0;32m     18\u001b[0m     )\n\u001b[0;32m     20\u001b[0m second_response\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    211\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    221\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    222\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    229\u001b[0m     )\n\u001b[1;32m--> 230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    618\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    619\u001b[0m         )\n\u001b[0;32m    620\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    621\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    629\u001b[0m         ),\n\u001b[0;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    631\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    689\u001b[0m     )\n\u001b[0;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: {'name': None, 'price': '10.99'} is not of type 'string' - 'messages.2.content'"
     ]
    }
   ],
   "source": [
    "if message.get(\"function_call\"):\n",
    "    function_name = message[\"function_call\"][\"name\"]\n",
    "    function_response = get_pizza_info(\n",
    "        pizza_name=message.get(\"pizza_name\"),\n",
    "    )\n",
    "\n",
    "    second_response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "            message,\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "second_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain \n",
    "\n",
    "LangChain allows you to use functions too, but currently (15.06.2023) it is kind of hacky to do it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0613\")\n",
    "message = llm.predict_messages(\n",
    "    [HumanMessage(content=\"What is the capital of france?\")], functions=functions\n",
    ")\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How much does Pizza Salami cost in the restaurant?\"\n",
    "message_pizza = llm.predict_messages([HumanMessage(content=query)], functions=functions)\n",
    "message_pizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(message_pizza.additional_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_response = llm.predict_messages(\n",
    "    [\n",
    "        HumanMessage(content=query),\n",
    "        AIMessage(content=str(message_pizza.additional_kwargs)),\n",
    "        ChatMessage(\n",
    "            role=\"function\",\n",
    "            additional_kwargs={\n",
    "                \"name\": message_pizza.additional_kwargs[\"function_call\"][\"name\"]\n",
    "            },\n",
    "            content=query,\n",
    "        ),\n",
    "    ],\n",
    "    functions=functions,\n",
    ")\n",
    "second_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Tools\n",
    "\n",
    "You can convert Tools to functions, both the Tools provided by langchain and also your own tools. The Tool you see is there to show you the interface of a tool, it actually does nothing really do anything useful ;-) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "\n",
    "\n",
    "class StupidJokeTool(BaseTool):\n",
    "    name = \"StupidJokeTool\"\n",
    "    description = \"Tool to explain stupid jokes\"\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        return f\"LOL: {query}\"\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"joke tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import format_tool_to_openai_function, MoveFileTool\n",
    "\n",
    "\n",
    "tools = [StupidJokeTool(), MoveFileTool()]\n",
    "functions = [format_tool_to_openai_function(t) for t in tools]\n",
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Why does the chicken cross the road? To get to the other side\"\n",
    "output = llm.predict_messages([HumanMessage(content=query)], functions=functions)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_response = llm.predict_messages(\n",
    "    [\n",
    "        HumanMessage(content=query),\n",
    "        AIMessage(content=str(output.additional_kwargs)),\n",
    "        ChatMessage(\n",
    "            role=\"function\",\n",
    "            additional_kwargs={\n",
    "                \"name\": output.additional_kwargs[\"function_call\"][\"name\"]\n",
    "            },\n",
    "            content=\"\"\"\n",
    "                {query}\n",
    "            \"\"\",\n",
    "        ),\n",
    "    ],\n",
    "    functions=functions,\n",
    ")\n",
    "second_response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
